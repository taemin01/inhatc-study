{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a3fbd7bd",
      "metadata": {
        "id": "a3fbd7bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m60\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m220\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">721</span> (2.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m721\u001b[0m (2.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">721</span> (2.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m721\u001b[0m (2.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 347ms/step - loss: 46391021568.0000\n",
            "Epoch 1: val_loss improved from inf to 40068235264.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38669152256.0000 - val_loss: 40068235264.0000\n",
            "Epoch 2/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 39409774592.0000\n",
            "Epoch 2: val_loss improved from 40068235264.00000 to 39161876480.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37962584064.0000 - val_loss: 39161876480.0000\n",
            "Epoch 3/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 27146121216.0000\n",
            "Epoch 3: val_loss improved from 39161876480.00000 to 36632281088.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34610057216.0000 - val_loss: 36632281088.0000\n",
            "Epoch 4/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 42118176768.0000\n",
            "Epoch 4: val_loss improved from 36632281088.00000 to 30273675264.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33140840448.0000 - val_loss: 30273675264.0000\n",
            "Epoch 5/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 36435275776.0000\n",
            "Epoch 5: val_loss improved from 30273675264.00000 to 18796644352.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27406374912.0000 - val_loss: 18796644352.0000\n",
            "Epoch 6/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 15465182208.0000\n",
            "Epoch 6: val_loss improved from 18796644352.00000 to 6954287616.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13975553024.0000 - val_loss: 6954287616.0000\n",
            "Epoch 7/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6321840128.0000\n",
            "Epoch 7: val_loss improved from 6954287616.00000 to 3776370176.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4668801024.0000 - val_loss: 3776370176.0000\n",
            "Epoch 8/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1083556992.0000\n",
            "Epoch 8: val_loss did not improve from 3776370176.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1733044608.0000 - val_loss: 3889830400.0000\n",
            "Epoch 9/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2454119936.0000\n",
            "Epoch 9: val_loss did not improve from 3776370176.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1947983488.0000 - val_loss: 3835019520.0000\n",
            "Epoch 10/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 907203968.0000\n",
            "Epoch 10: val_loss did not improve from 3776370176.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1776901504.0000 - val_loss: 3854019584.0000\n",
            "Epoch 11/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1187530112.0000\n",
            "Epoch 11: val_loss did not improve from 3776370176.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1895612032.0000 - val_loss: 3819349248.0000\n",
            "Epoch 12/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1210943872.0000\n",
            "Epoch 12: val_loss did not improve from 3776370176.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1941475456.0000 - val_loss: 3817050112.0000\n",
            "Epoch 13/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3081992448.0000\n",
            "Epoch 13: val_loss did not improve from 3776370176.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2103495168.0000 - val_loss: 3802541824.0000\n",
            "Epoch 14/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1781909248.0000\n",
            "Epoch 14: val_loss did not improve from 3776370176.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1848494336.0000 - val_loss: 3802558976.0000\n",
            "Epoch 15/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 466375776.0000\n",
            "Epoch 15: val_loss did not improve from 3776370176.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 1684170240.0000 - val_loss: 3814332928.0000\n",
            "Epoch 16/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3153981952.0000\n",
            "Epoch 16: val_loss did not improve from 3776370176.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2086004480.0000 - val_loss: 3780121344.0000\n",
            "Epoch 17/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3279553792.0000\n",
            "Epoch 17: val_loss improved from 3776370176.00000 to 3761563648.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1939950848.0000 - val_loss: 3761563648.0000\n",
            "Epoch 18/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2083180544.0000\n",
            "Epoch 18: val_loss improved from 3761563648.00000 to 3757038592.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2234831360.0000 - val_loss: 3757038592.0000\n",
            "Epoch 19/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1497282560.0000\n",
            "Epoch 19: val_loss did not improve from 3757038592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 1839058048.0000 - val_loss: 3768352256.0000\n",
            "Epoch 20/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 618937728.0000\n",
            "Epoch 20: val_loss improved from 3757038592.00000 to 3697234176.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1913765760.0000 - val_loss: 3697234176.0000\n",
            "Epoch 21/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2951299840.0000\n",
            "Epoch 21: val_loss did not improve from 3697234176.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2225815040.0000 - val_loss: 3710653952.0000\n",
            "Epoch 22/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 943528064.0000\n",
            "Epoch 22: val_loss did not improve from 3697234176.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1722164352.0000 - val_loss: 3742092032.0000\n",
            "Epoch 23/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2443452160.0000\n",
            "Epoch 23: val_loss improved from 3697234176.00000 to 3694310912.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2126146560.0000 - val_loss: 3694310912.0000\n",
            "Epoch 24/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2600559104.0000\n",
            "Epoch 24: val_loss improved from 3694310912.00000 to 3684544000.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1885615872.0000 - val_loss: 3684544000.0000\n",
            "Epoch 25/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7136138752.0000\n",
            "Epoch 25: val_loss did not improve from 3684544000.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 2182254592.0000 - val_loss: 3696861184.0000\n",
            "Epoch 26/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1815101824.0000\n",
            "Epoch 26: val_loss improved from 3684544000.00000 to 3664589568.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1784109824.0000 - val_loss: 3664589568.0000\n",
            "Epoch 27/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3040371712.0000\n",
            "Epoch 27: val_loss did not improve from 3664589568.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 1857454976.0000 - val_loss: 3688651520.0000\n",
            "Epoch 28/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2258855168.0000\n",
            "Epoch 28: val_loss did not improve from 3664589568.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 2012043904.0000 - val_loss: 3678250240.0000\n",
            "Epoch 29/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 688553664.0000\n",
            "Epoch 29: val_loss did not improve from 3664589568.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1619757696.0000 - val_loss: 3681602304.0000\n",
            "Epoch 30/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2346582016.0000\n",
            "Epoch 30: val_loss did not improve from 3664589568.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 1696254208.0000 - val_loss: 3678492928.0000\n",
            "Epoch 31/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1065303680.0000\n",
            "Epoch 31: val_loss did not improve from 3664589568.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1708115968.0000 - val_loss: 3668590336.0000\n",
            "Epoch 32/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2982955776.0000\n",
            "Epoch 32: val_loss improved from 3664589568.00000 to 3651115264.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2003612544.0000 - val_loss: 3651115264.0000\n",
            "Epoch 33/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1668898816.0000\n",
            "Epoch 33: val_loss improved from 3651115264.00000 to 3634330368.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1685395200.0000 - val_loss: 3634330368.0000\n",
            "Epoch 34/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2282130944.0000\n",
            "Epoch 34: val_loss did not improve from 3634330368.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2102525696.0000 - val_loss: 3655136512.0000\n",
            "Epoch 35/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2482002176.0000\n",
            "Epoch 35: val_loss did not improve from 3634330368.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 1882498688.0000 - val_loss: 3637019648.0000\n",
            "Epoch 36/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2738551552.0000\n",
            "Epoch 36: val_loss improved from 3634330368.00000 to 3576587008.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2033969152.0000 - val_loss: 3576587008.0000\n",
            "Epoch 37/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4369124352.0000\n",
            "Epoch 37: val_loss did not improve from 3576587008.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2094568832.0000 - val_loss: 3632163072.0000\n",
            "Epoch 38/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2432232960.0000\n",
            "Epoch 38: val_loss did not improve from 3576587008.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 1903513984.0000 - val_loss: 3593254400.0000\n",
            "Epoch 39/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2835534848.0000\n",
            "Epoch 39: val_loss improved from 3576587008.00000 to 3568244736.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1986063104.0000 - val_loss: 3568244736.0000\n",
            "Epoch 40/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3549842944.0000\n",
            "Epoch 40: val_loss improved from 3568244736.00000 to 3565053440.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1986168832.0000 - val_loss: 3565053440.0000\n",
            "Epoch 41/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 653578560.0000\n",
            "Epoch 41: val_loss did not improve from 3565053440.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1814464640.0000 - val_loss: 3593558016.0000\n",
            "Epoch 42/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3633148416.0000\n",
            "Epoch 42: val_loss improved from 3565053440.00000 to 3563979520.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1965940352.0000 - val_loss: 3563979520.0000\n",
            "Epoch 43/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 619155840.0000\n",
            "Epoch 43: val_loss did not improve from 3563979520.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1649576064.0000 - val_loss: 3610070784.0000\n",
            "Epoch 44/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1968691200.0000\n",
            "Epoch 44: val_loss improved from 3563979520.00000 to 3554471424.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1891427584.0000 - val_loss: 3554471424.0000\n",
            "Epoch 45/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 882188800.0000\n",
            "Epoch 45: val_loss did not improve from 3554471424.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1739047936.0000 - val_loss: 3576493312.0000\n",
            "Epoch 46/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1467083776.0000\n",
            "Epoch 46: val_loss improved from 3554471424.00000 to 3551776512.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2009451008.0000 - val_loss: 3551776512.0000\n",
            "Epoch 47/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1910682880.0000\n",
            "Epoch 47: val_loss improved from 3551776512.00000 to 3539662848.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1910428032.0000 - val_loss: 3539662848.0000\n",
            "Epoch 48/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3715062528.0000\n",
            "Epoch 48: val_loss did not improve from 3539662848.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1885347712.0000 - val_loss: 3556866560.0000\n",
            "Epoch 49/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1852668288.0000\n",
            "Epoch 49: val_loss did not improve from 3539662848.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1711175552.0000 - val_loss: 3555638016.0000\n",
            "Epoch 50/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4431309312.0000\n",
            "Epoch 50: val_loss improved from 3539662848.00000 to 3508827392.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2045732352.0000 - val_loss: 3508827392.0000\n",
            "Epoch 51/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1653567488.0000\n",
            "Epoch 51: val_loss did not improve from 3508827392.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1809200000.0000 - val_loss: 3583691520.0000\n",
            "Epoch 52/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2316167936.0000\n",
            "Epoch 52: val_loss did not improve from 3508827392.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 1967109504.0000 - val_loss: 3530562560.0000\n",
            "Epoch 53/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1332706048.0000\n",
            "Epoch 53: val_loss did not improve from 3508827392.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1704118528.0000 - val_loss: 3511968768.0000\n",
            "Epoch 54/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 970914624.0000\n",
            "Epoch 54: val_loss did not improve from 3508827392.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 1619331072.0000 - val_loss: 3515669504.0000\n",
            "Epoch 55/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1378558592.0000\n",
            "Epoch 55: val_loss improved from 3508827392.00000 to 3504846080.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1665785344.0000 - val_loss: 3504846080.0000\n",
            "Epoch 56/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 681925504.0000\n",
            "Epoch 56: val_loss did not improve from 3504846080.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 1708401408.0000 - val_loss: 3550895360.0000\n",
            "Epoch 57/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1758657792.0000\n",
            "Epoch 57: val_loss improved from 3504846080.00000 to 3498694912.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1814249600.0000 - val_loss: 3498694912.0000\n",
            "Epoch 58/2000\n",
            "\u001b[1m20/44\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1915518080.0000 \n",
            "Epoch 58: val_loss did not improve from 3498694912.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1863558656.0000 - val_loss: 3500333824.0000\n",
            "Epoch 59/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3637734656.0000\n",
            "Epoch 59: val_loss did not improve from 3498694912.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1835534464.0000 - val_loss: 3509868032.0000\n",
            "Epoch 60/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1571513216.0000\n",
            "Epoch 60: val_loss did not improve from 3498694912.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 1669935872.0000 - val_loss: 3518255616.0000\n",
            "Epoch 61/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1671128832.0000\n",
            "Epoch 61: val_loss improved from 3498694912.00000 to 3472259328.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1757785984.0000 - val_loss: 3472259328.0000\n",
            "Epoch 62/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1775705088.0000\n",
            "Epoch 62: val_loss did not improve from 3472259328.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1708350080.0000 - val_loss: 3476394752.0000\n",
            "Epoch 63/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1484637440.0000\n",
            "Epoch 63: val_loss improved from 3472259328.00000 to 3463209216.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1676473856.0000 - val_loss: 3463209216.0000\n",
            "Epoch 64/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1681297920.0000\n",
            "Epoch 64: val_loss did not improve from 3463209216.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1661492864.0000 - val_loss: 3489583872.0000\n",
            "Epoch 65/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3383973888.0000\n",
            "Epoch 65: val_loss improved from 3463209216.00000 to 3462053120.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1853025024.0000 - val_loss: 3462053120.0000\n",
            "Epoch 66/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 852820672.0000\n",
            "Epoch 66: val_loss did not improve from 3462053120.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1634356992.0000 - val_loss: 3486490880.0000\n",
            "Epoch 67/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1816296192.0000\n",
            "Epoch 67: val_loss did not improve from 3462053120.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 1775012608.0000 - val_loss: 3470343424.0000\n",
            "Epoch 68/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 920450560.0000\n",
            "Epoch 68: val_loss did not improve from 3462053120.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 1698951936.0000 - val_loss: 3500888320.0000\n",
            "Epoch 69/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1675004288.0000\n",
            "Epoch 69: val_loss did not improve from 3462053120.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 1772521984.0000 - val_loss: 3508243712.0000\n",
            "Epoch 70/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2672316928.0000\n",
            "Epoch 70: val_loss did not improve from 3462053120.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 1912080768.0000 - val_loss: 3492513280.0000\n",
            "Epoch 71/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1915367040.0000\n",
            "Epoch 71: val_loss improved from 3462053120.00000 to 3458585600.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1942710144.0000 - val_loss: 3458585600.0000\n",
            "Epoch 72/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1179863808.0000\n",
            "Epoch 72: val_loss did not improve from 3458585600.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1508521856.0000 - val_loss: 3517766656.0000\n",
            "Epoch 73/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1787187840.0000\n",
            "Epoch 73: val_loss did not improve from 3458585600.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 1964808832.0000 - val_loss: 3527050240.0000\n",
            "Epoch 74/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1618651520.0000\n",
            "Epoch 74: val_loss did not improve from 3458585600.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 1573470592.0000 - val_loss: 3507890176.0000\n",
            "Epoch 75/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2434902528.0000\n",
            "Epoch 75: val_loss did not improve from 3458585600.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 1840652416.0000 - val_loss: 3489931520.0000\n",
            "Epoch 76/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2361967104.0000\n",
            "Epoch 76: val_loss improved from 3458585600.00000 to 3419538688.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1958991232.0000 - val_loss: 3419538688.0000\n",
            "Epoch 77/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2039215360.0000\n",
            "Epoch 77: val_loss did not improve from 3419538688.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1823382912.0000 - val_loss: 3483877888.0000\n",
            "Epoch 78/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1003333760.0000\n",
            "Epoch 78: val_loss did not improve from 3419538688.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 1569014272.0000 - val_loss: 3436125440.0000\n",
            "Epoch 79/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 688725248.0000\n",
            "Epoch 79: val_loss did not improve from 3419538688.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1419900672.0000 - val_loss: 3496421120.0000\n",
            "Epoch 80/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2561093120.0000\n",
            "Epoch 80: val_loss did not improve from 3419538688.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 1882408320.0000 - val_loss: 3459343872.0000\n",
            "Epoch 81/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1476737664.0000\n",
            "Epoch 81: val_loss did not improve from 3419538688.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 1684983680.0000 - val_loss: 3459677184.0000\n",
            "Epoch 82/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1576291072.0000\n",
            "Epoch 82: val_loss did not improve from 3419538688.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 1843723136.0000 - val_loss: 3445704192.0000\n",
            "Epoch 83/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2635018752.0000\n",
            "Epoch 83: val_loss did not improve from 3419538688.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 1840832384.0000 - val_loss: 3442599424.0000\n",
            "Epoch 84/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2666658560.0000\n",
            "Epoch 84: val_loss did not improve from 3419538688.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 1812490368.0000 - val_loss: 3488063744.0000\n",
            "Epoch 85/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1201050624.0000\n",
            "Epoch 85: val_loss improved from 3419538688.00000 to 3411550464.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1517494656.0000 - val_loss: 3411550464.0000\n",
            "Epoch 86/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1459388672.0000\n",
            "Epoch 86: val_loss did not improve from 3411550464.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 1904968704.0000 - val_loss: 3430901760.0000\n",
            "Epoch 87/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 838604288.0000\n",
            "Epoch 87: val_loss did not improve from 3411550464.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 1833929856.0000 - val_loss: 3494808320.0000\n",
            "Epoch 88/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1413352448.0000\n",
            "Epoch 88: val_loss did not improve from 3411550464.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 1691766272.0000 - val_loss: 3420984320.0000\n",
            "Epoch 89/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2016537600.0000\n",
            "Epoch 89: val_loss did not improve from 3411550464.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 1568864000.0000 - val_loss: 3473949440.0000\n",
            "Epoch 90/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1187417856.0000\n",
            "Epoch 90: val_loss did not improve from 3411550464.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1707266304.0000 - val_loss: 3414858240.0000\n",
            "Epoch 91/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3772701440.0000\n",
            "Epoch 91: val_loss improved from 3411550464.00000 to 3404669696.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2100196224.0000 - val_loss: 3404669696.0000\n",
            "Epoch 92/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1782176000.0000\n",
            "Epoch 92: val_loss improved from 3404669696.00000 to 3402603008.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1718518400.0000 - val_loss: 3402603008.0000\n",
            "Epoch 93/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1696795904.0000\n",
            "Epoch 93: val_loss did not improve from 3402603008.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2022156032.0000 - val_loss: 3445770496.0000\n",
            "Epoch 94/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 566287168.0000\n",
            "Epoch 94: val_loss did not improve from 3402603008.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1812389120.0000 - val_loss: 3410949888.0000\n",
            "Epoch 95/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2268442112.0000\n",
            "Epoch 95: val_loss did not improve from 3402603008.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 1603979008.0000 - val_loss: 3444430336.0000\n",
            "Epoch 96/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1696066432.0000\n",
            "Epoch 96: val_loss did not improve from 3402603008.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 1663822208.0000 - val_loss: 3424819200.0000\n",
            "Epoch 97/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1363603840.0000\n",
            "Epoch 97: val_loss improved from 3402603008.00000 to 3352558592.00000, saving model to house2.keras\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1873288448.0000 - val_loss: 3352558592.0000\n",
            "Epoch 98/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1798143616.0000\n",
            "Epoch 98: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1979531392.0000 - val_loss: 3401178624.0000\n",
            "Epoch 99/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 858089344.0000\n",
            "Epoch 99: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1634176640.0000 - val_loss: 3412346624.0000\n",
            "Epoch 100/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 983679488.0000\n",
            "Epoch 100: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1622589568.0000 - val_loss: 3490043648.0000\n",
            "Epoch 101/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1991362560.0000\n",
            "Epoch 101: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1701653376.0000 - val_loss: 3385444352.0000\n",
            "Epoch 102/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 981262528.0000\n",
            "Epoch 102: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1798977280.0000 - val_loss: 3368028928.0000\n",
            "Epoch 103/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2802180864.0000\n",
            "Epoch 103: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1949080064.0000 - val_loss: 3413502976.0000\n",
            "Epoch 104/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3645908224.0000\n",
            "Epoch 104: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1948069760.0000 - val_loss: 3361730048.0000\n",
            "Epoch 105/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1833691776.0000\n",
            "Epoch 105: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1670674048.0000 - val_loss: 3431128576.0000\n",
            "Epoch 106/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1778238208.0000\n",
            "Epoch 106: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1648665088.0000 - val_loss: 3407149568.0000\n",
            "Epoch 107/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1182844160.0000\n",
            "Epoch 107: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 1705494656.0000 - val_loss: 3372835584.0000\n",
            "Epoch 108/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2038999040.0000\n",
            "Epoch 108: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 1678009984.0000 - val_loss: 3413122304.0000\n",
            "Epoch 109/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1436456192.0000\n",
            "Epoch 109: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 1782991488.0000 - val_loss: 3412500480.0000\n",
            "Epoch 110/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3048658432.0000\n",
            "Epoch 110: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 1885431552.0000 - val_loss: 3394873344.0000\n",
            "Epoch 111/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2440064256.0000\n",
            "Epoch 111: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 1830847488.0000 - val_loss: 3369234432.0000\n",
            "Epoch 112/2000\n",
            "\u001b[1m 1/44\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1779225984.0000\n",
            "Epoch 112: val_loss did not improve from 3352558592.00000\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1713815168.0000 - val_loss: 3392622336.0000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "실제가격: 251000.00, 예상가격: 216643.42\n",
            "실제가격: 81000.00, 예상가격: 103290.45\n",
            "실제가격: 109000.00, 예상가격: 137659.61\n",
            "실제가격: 265000.00, 예상가격: 277242.59\n",
            "실제가격: 375000.00, 예상가격: 273409.06\n",
            "실제가격: 239900.00, 예상가격: 219194.42\n",
            "실제가격: 119500.00, 예상가격: 128752.03\n",
            "실제가격: 134500.00, 예상가격: 131948.59\n",
            "실제가격: 135000.00, 예상가격: 144976.45\n",
            "실제가격: 220000.00, 예상가격: 201711.41\n",
            "실제가격: 134800.00, 예상가격: 148258.86\n",
            "실제가격: 252000.00, 예상가격: 258279.86\n",
            "실제가격: 755000.00, 예상가격: 448282.16\n",
            "실제가격: 148000.00, 예상가격: 167227.75\n",
            "실제가격: 174000.00, 예상가격: 151924.45\n",
            "실제가격: 159500.00, 예상가격: 149408.12\n",
            "실제가격: 94000.00, 예상가격: 100226.80\n",
            "실제가격: 167000.00, 예상가격: 207398.70\n",
            "실제가격: 207000.00, 예상가격: 182199.30\n",
            "실제가격: 179600.00, 예상가격: 210156.05\n",
            "실제가격: 244000.00, 예상가격: 204074.20\n",
            "실제가격: 158000.00, 예상가격: 208187.64\n",
            "실제가격: 302000.00, 예상가격: 254390.45\n",
            "실제가격: 185000.00, 예상가격: 211285.70\n",
            "실제가격: 113000.00, 예상가격: 94168.14\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#데이터를 불러 옵니다.\n",
        "df = pd.read_csv(\"house_data.csv\")\n",
        "\n",
        "#카테고리형 변수를 0과 1로 이루어진 변수로 바꾸어 줍니다.(12장 3절)\n",
        "df = pd.get_dummies(df)\n",
        "\n",
        "#결측치를 전체 칼럼의 평균으로 대체하여 채워줍니다.\n",
        "df = df.fillna(df.mean())\n",
        "\n",
        "#업데이트된 데이터프레임을 출력해 봅니다.\n",
        "#df\n",
        "#집 값을 제외한 나머지 열을 저장합니다.\n",
        "cols_train=['OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF']\n",
        "X_train_pre = df[cols_train]\n",
        "\n",
        "#집 값을 저장합니다.\n",
        "y = df['SalePrice'].values\n",
        "X_train_pre=X_train_pre.astype(float)\n",
        "y=y.astype(float)\n",
        "#전체의 80%를 학습셋으로, 20%를 테스트셋으로 지정합니다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_pre, y, test_size=0.2)\n",
        "#모델의 구조를 설정합니다.\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))  \n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "\n",
        "#모델을 실행합니다.\n",
        "model.compile(optimizer ='adam', loss = 'mean_squared_error')\n",
        "\n",
        "# n회 이상 결과가 향상되지 않으면 자동으로 중단되게끔 합니다.\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=15)\n",
        "\n",
        "# 모델의 이름을 정합니다.\n",
        "modelpath=\"house2.keras\"\n",
        "\n",
        "# 최적화 모델을 업데이트하고 저장합니다.\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "#실행 관련 설정을 하는 부분입니다. 전체의 20%를 검증셋으로 설정합니다.\n",
        "history = model.fit(X_train, y_train, validation_split=0.25, epochs=2000, batch_size=20, callbacks=[early_stopping_callback, checkpointer])\n",
        "# 예측 값과 실제 값, 실행 번호가 들어갈 빈 리스트를 만듭니다.\n",
        "real_prices =[]\n",
        "pred_prices = []\n",
        "X_num = []\n",
        "\n",
        "\n",
        "\n",
        "# 25개의 샘플을 뽑아 실제 값, 예측 값을 출력해 봅니다.\n",
        "n_iter = 0\n",
        "Y_prediction = model.predict(X_test).flatten()\n",
        "for i in range(25):\n",
        "    real = y_test[i]\n",
        "    prediction = Y_prediction[i]\n",
        "    print(\"실제가격: {:.2f}, 예상가격: {:.2f}\".format(real, prediction))\n",
        "    real_prices.append(real)\n",
        "    pred_prices.append(prediction)\n",
        "    n_iter = n_iter + 1\n",
        "    X_num.append(n_iter)\n",
        "#그래프를 통해 샘플로 뽑은 25개의 값을 비교해 봅니다.\n",
        "\n",
        "plt.plot(X_num, pred_prices, label='predicted price')\n",
        "plt.plot(X_num, real_prices, label='real price')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fPIPdAlkLvoc",
      "metadata": {
        "id": "fPIPdAlkLvoc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3810161920.0000 \n",
            "테스트 loss1 :  311.6849152\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4072756224.0000 \n",
            "테스트 loss2 :  335.177472\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_pre, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "model = load_model('house1.keras')\n",
        "print('테스트 loss1 : ', model.evaluate(X_test, y_test) / 10000000)\n",
        "\n",
        "model = load_model('house2.keras')\n",
        "print('테스트 loss2 : ', model.evaluate(X_test, y_test) / 10000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AXuryYJzgtxM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXuryYJzgtxM",
        "outputId": "106a75be-5dea-443c-98d5-f78317378d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 2231532544.0000\n",
            "테스트 loss 223.1532544\n"
          ]
        }
      ],
      "source": [
        "print('테스트 loss', model.evaluate(X_test,y_test)/10000000)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
